{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import altair as alt\n",
    "alt.renderers.enable('notebook')\n",
    "alt.data_transformers.enable('default', max_rows=None)\n",
    "\n",
    "from utils import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_json(path='C:/Users/chladek/Documents/github/exponea/exponea_prediction_dummy_data/campaign.json')\n",
    "df = rem_const(df)\n",
    "# for easier exploration\n",
    "df.drop(['recipient','language'],1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('2018-03-17 07:05:28.764564037'),\n",
       " Timestamp('2018-05-16 06:50:46.329377890')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking for timerange - would be crucial if seasonality is considered\n",
    "[df.iloc[0,:].date,df.iloc[-1,:].date]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://knowledge.hubspot.com/email-user-guide-v2/understanding-email-deliverability\n",
    "# query just emails since opened/clicked except for 2 instances (pushweb) are only emails\n",
    "# that means action_type ='split' => status ='failed' are out in that case\n",
    "\n",
    "strng = 'email'\n",
    "df = df.query(\"(action_type == @strng)\")\n",
    "df.drop('action_type', 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other statuses shouldn't matter\n",
    "\n",
    "strng = \"delivered\"\n",
    "strng1 = 'opened'\n",
    "strng2 = 'clicked'\n",
    "sample = df.query(\"status == @strng | status == @strng1 | status == @strng2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create unique identifier for customer + campaign\n",
    "sample['unique_id'] = sample['customer_id'].map(str) + sample['campaign_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to drop completely duplicated rows\n",
    "sample.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop 'clicked' to unsubscribe since this is not positive response\n",
    "sample = sample[~sample['url'].str.contains(\"unsubscribe\",na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare df for loop to be in correct order\n",
    "sample = sample.sort_values(by=['unique_id','date'])\n",
    "sample.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tryng to iterate over rows and look if in sorted df\n",
    "# row of same customer below is success given current row is delivered\n",
    "# if not we consider unsuccess\n",
    "output = []\n",
    "val = None\n",
    "for i, row in sample.iterrows():\n",
    "    #print(i)\n",
    "    #print(sample.loc[i,:])\n",
    "    # only delivered can be opened/clicked\n",
    "    if (row.status == 'delivered') & (i < len(sample)-1):\n",
    "        #since we sorted by id & date we row below has to be opened/clicked\n",
    "        # to be success\n",
    "        if (sample.loc[i+1,:].status != 'delivered') & (row.unique_id == sample.loc[i+1,:].unique_id):\n",
    "            val = 1\n",
    "        else:\n",
    "            val = 0\n",
    "    else:\n",
    "        val = 0\n",
    "    output.append(val)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign response variable\n",
    "sample['response'] = output\n",
    "sample['hour'] = sample.date.dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take just training instances\n",
    "strng = 'delivered'\n",
    "df = sample.query('status == @strng')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Purchased item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is more of pipeline for future predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchased = load_json(path='exponea_prediction_dummy_data/purchase_item.json')\n",
    "prch = rem_const(purchased)\n",
    "prch['freq'] = prch.groupby('customer_id')['customer_id'].transform('count')\n",
    "prch['last'] = prch.groupby('customer_id')['date'].transform('last')\n",
    "prch.sort_values(by=['customer_id','date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean difference in minutes between puchases for each customer\n",
    "prch['diff'] = prch.groupby(['customer_id'])['date'].transform(lambda x: x.diff().dt.seconds.div(60))\n",
    "prch['mean_diff'] = prch.groupby('customer_id')['diff'].transform('mean').fillna(0)\n",
    "prch.drop('diff', 1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cart update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart = load_json(path='exponea_prediction_dummy_data/cart_update.json')\n",
    "cart = rem_const(cart)\n",
    "cart['freq'] = cart.groupby('customer_id')['customer_id'].transform('count')\n",
    "cart['last'] = cart.groupby('customer_id')['date'].transform('last')\n",
    "cart.sort_values(by=['customer_id','date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean difference in minutes between cart updates for each customer\n",
    "cart['diff'] = cart.groupby(['customer_id'])['date'].transform(lambda x: x.diff().dt.seconds.div(60))\n",
    "cart['mean_diff'] = cart.groupby('customer_id')['diff'].transform('mean').fillna(0)\n",
    "cart.drop('diff', 1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Email openings metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many unique campaign customer opened and with what mean differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "strng = 'clicked'\n",
    "strng1 = 'opened'\n",
    "sample = sample.query('status == @strng | status ==@strng1')\n",
    "sample.sort_values(by='date',inplace=True)\n",
    "email = sample[~sample.duplicated(subset='unique_id')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email['freq'] = email.groupby('customer_id')['customer_id'].transform('count')\n",
    "email['last'] = email.groupby('customer_id')['date'].transform('last')\n",
    "email.sort_values(by=['customer_id','date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean difference in minutes between oepened/clicked emails for each customer \n",
    "email['diff'] = email.groupby(['customer_id'])['date'].transform(lambda x: x.diff().dt.seconds.div(60))\n",
    "email['mean_diff'] = email.groupby('customer_id')['diff'].transform('mean').fillna(0)\n",
    "email.drop('diff', 1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping sets of features to each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take delivered email.date load datatsets and recalculate\n",
    "# for corner cases we will use Naive population model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prch\n",
    "purchased = load_json(path='exponea_prediction_dummy_data/purchase_item.json')\n",
    "prch = rem_const(purchased)\n",
    "\n",
    "# cart\n",
    "cart = load_json(path='exponea_prediction_dummy_data/cart_update.json')\n",
    "cart = rem_const(cart)\n",
    "\n",
    "# view\n",
    "view = load_json(path='exponea_prediction_dummy_data/view_product.json')\n",
    "view.drop('eans',1,inplace=True)\n",
    "view = rem_const(view)\n",
    "\n",
    "# session_start\n",
    "sess = load_json(path='exponea_prediction_dummy_data/session_start.json')\n",
    "sess = rem_const(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below takes unreasonably long so run it only on dataset\n",
    "\n",
    "prch_feats = []\n",
    "cart_feats = []\n",
    "view_feats = []\n",
    "sess_feats = []\n",
    "email_feats = []\n",
    "\n",
    "for i,row in df.iterrows():\n",
    "    print(i)\n",
    "    # for each row create subset that was actual in time of the email\n",
    "    temp1 = prch[(prch.date < row.date) & (prch.customer_id == row.customer_id)]\n",
    "    prch_feats.append(add_metrics(temp1))\n",
    "    \n",
    "    temp2 = cart[(cart.date < row.date) & (cart.customer_id == row.customer_id)]\n",
    "    cart_feats.append(add_metrics(temp2))\n",
    "    \n",
    "    temp3 = view[(view.date < row.date) & (view.customer_id == row.customer_id)]\n",
    "    view_feats.append(add_metrics(temp3))\n",
    "    \n",
    "    temp4 = sess[(sess.date < row.date) & (sess.customer_id == row.customer_id)]\n",
    "    sess_feats.append(add_metrics(temp4))\n",
    "    \n",
    "    temp5 = email[(email.date < row.date) & (email.customer_id == row.customer_id)]\n",
    "    email_feats.append(add_metrics(temp5))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = prch_feats\n",
    "b = cart_feats\n",
    "c = view_feats\n",
    "d = sess_feats\n",
    "e = email_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# in seconds but probably will need to be updated\n",
    "dataset['prch_freq'] = list(zip(*a))[0]\n",
    "dataset['prch_last'] = (dataset.date - pd.to_datetime(list(zip(*a))[1],errors='coerce')).dt.seconds.fillna(0).div(60)\n",
    "dataset['prch_mean_diff'] = list(zip(*a))[2]\n",
    "\n",
    "dataset['cart_freq'] = list(zip(*b))[0]\n",
    "dataset['cart_last'] = (dataset.date - pd.to_datetime(list(zip(*b))[1],errors='coerce')).dt.seconds.fillna(0).div(60)\n",
    "dataset['cart_mean_diff'] = list(zip(*b))[2]\n",
    "\n",
    "\n",
    "dataset['view_freq'] = list(zip(*c))[0]\n",
    "dataset['view_last'] = (dataset.date - pd.to_datetime(list(zip(*c))[1],errors='coerce')).dt.seconds.fillna(0).div(60)\n",
    "dataset['view_mean_diff'] = list(zip(*c))[2]\n",
    "\n",
    "\n",
    "dataset['sess_freq'] = list(zip(*d))[0]\n",
    "dataset['sess_last'] = (dataset.date - pd.to_datetime(list(zip(*d))[1],errors='coerce')).dt.seconds.fillna(0).div(60)\n",
    "dataset['sess_mean_diff'] = list(zip(*d))[2]\n",
    "\n",
    "\n",
    "dataset['email_freq'] = list(zip(*e))[0]\n",
    "dataset['email_last'] = (dataset.date - pd.to_datetime(list(zip(*e))[1],errors='coerce')).dt.seconds.fillna(0).div(60)\n",
    "dataset['email_mean_diff'] = list(zip(*e))[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = load_json(path='C:/Users/chladek/Documents/github/exponea/exponea_prediction_dummy_data/campaign.json')\n",
    "df = rem_const(df)\n",
    "# for easier exploration\n",
    "df.drop(['recipient','language'],1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = load_json(path='C:/Users/chladek/Documents/github/exponea/exponea_prediction_dummy_data/purchase_item.json')\n",
    "pi = rem_const(pi)\n",
    "# for easier exploration\n",
    "#pi.drop(['recipient','language'],1,inplace=True)\n",
    "pi['status'] = 'pitem'\n",
    "pi['action_type'] = 'purchase'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chladek\\AppData\\Local\\Continuum\\anaconda3-64\\envs\\tf\\lib\\site-packages\\ipykernel\\__main__.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([df,pi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OLD PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://knowledge.hubspot.com/email-user-guide-v2/understanding-email-deliverability\n",
    "\n",
    "strng = 'email'\n",
    "strng2 = 'purchase'\n",
    "df = df.query(\"(action_type == @strng | action_type == @strng2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other statuses shouldn't matter\n",
    "\n",
    "strng = \"delivered\"\n",
    "strng1 = 'opened'\n",
    "strng2 = 'clicked'\n",
    "strng3 = 'pitem'\n",
    "sample = df.query(\"status == @strng | status == @strng1 | status == @strng2 | status==@strng3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chladek\\AppData\\Local\\Continuum\\anaconda3-64\\envs\\tf\\lib\\site-packages\\ipykernel\\__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\chladek\\AppData\\Local\\Continuum\\anaconda3-64\\envs\\tf\\lib\\site-packages\\ipykernel\\__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# create unique identifier for customer + campaign\n",
    "sample['unique_id'] = sample['customer_id'].map(str) + sample['campaign_id']\n",
    "\n",
    "# need to drop duplated rows\n",
    "sample.drop_duplicates(inplace=True)\n",
    "\n",
    "# drop clicked to unsubscribe since this is not positive response\n",
    "sample = sample[~sample['url'].str.contains(\"unsubscribe\",na=False)]\n",
    "\n",
    "# prepare df for loop to be in correct order\n",
    "\n",
    "sample = sample.sort_values(by=['unique_id','date'])\n",
    "sample.reset_index(inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
